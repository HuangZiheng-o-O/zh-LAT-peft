{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 1710,
  "global_step": 17100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03,
      "grad_norm": 5.0625,
      "learning_rate": 0.00029912280701754386,
      "loss": 4.5412,
      "step": 50
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.337890625,
      "learning_rate": 0.0002982456140350877,
      "loss": 0.419,
      "step": 100
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.080078125,
      "learning_rate": 0.00029736842105263157,
      "loss": 0.2071,
      "step": 150
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.494140625,
      "learning_rate": 0.0002964912280701754,
      "loss": 0.1728,
      "step": 200
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.333984375,
      "learning_rate": 0.0002956140350877193,
      "loss": 0.1885,
      "step": 250
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.5,
      "learning_rate": 0.0002947368421052631,
      "loss": 0.2071,
      "step": 300
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.1484375,
      "learning_rate": 0.000293859649122807,
      "loss": 0.2112,
      "step": 350
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.349609375,
      "learning_rate": 0.00029298245614035087,
      "loss": 0.1969,
      "step": 400
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.2216796875,
      "learning_rate": 0.0002921052631578947,
      "loss": 0.2046,
      "step": 450
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.396484375,
      "learning_rate": 0.0002912280701754386,
      "loss": 0.1851,
      "step": 500
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.44921875,
      "learning_rate": 0.0002903508771929824,
      "loss": 0.1957,
      "step": 550
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0859375,
      "learning_rate": 0.0002894736842105263,
      "loss": 0.2019,
      "step": 600
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.1767578125,
      "learning_rate": 0.00028859649122807017,
      "loss": 0.1588,
      "step": 650
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.8515625,
      "learning_rate": 0.000287719298245614,
      "loss": 0.169,
      "step": 700
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.40625,
      "learning_rate": 0.0002868421052631579,
      "loss": 0.1866,
      "step": 750
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1328125,
      "learning_rate": 0.0002859649122807017,
      "loss": 0.1662,
      "step": 800
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.384765625,
      "learning_rate": 0.0002850877192982456,
      "loss": 0.1704,
      "step": 850
    },
    {
      "epoch": 0.53,
      "grad_norm": 0.091796875,
      "learning_rate": 0.0002842105263157894,
      "loss": 0.1548,
      "step": 900
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.318359375,
      "learning_rate": 0.0002833333333333333,
      "loss": 0.1442,
      "step": 950
    },
    {
      "epoch": 0.58,
      "grad_norm": 0.51953125,
      "learning_rate": 0.0002824561403508772,
      "loss": 0.144,
      "step": 1000
    },
    {
      "epoch": 0.61,
      "grad_norm": 0.32421875,
      "learning_rate": 0.00028157894736842106,
      "loss": 0.1777,
      "step": 1050
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.61328125,
      "learning_rate": 0.0002807017543859649,
      "loss": 0.1666,
      "step": 1100
    },
    {
      "epoch": 0.67,
      "grad_norm": 0.345703125,
      "learning_rate": 0.0002798245614035087,
      "loss": 0.1596,
      "step": 1150
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.5703125,
      "learning_rate": 0.0002789473684210526,
      "loss": 0.1398,
      "step": 1200
    },
    {
      "epoch": 0.73,
      "grad_norm": 0.1640625,
      "learning_rate": 0.0002780701754385965,
      "loss": 0.128,
      "step": 1250
    },
    {
      "epoch": 0.76,
      "grad_norm": 0.40625,
      "learning_rate": 0.0002771929824561403,
      "loss": 0.1483,
      "step": 1300
    },
    {
      "epoch": 0.79,
      "grad_norm": 0.298828125,
      "learning_rate": 0.0002763157894736842,
      "loss": 0.1383,
      "step": 1350
    },
    {
      "epoch": 0.82,
      "grad_norm": 1.140625,
      "learning_rate": 0.000275438596491228,
      "loss": 0.1413,
      "step": 1400
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6875,
      "learning_rate": 0.0002745614035087719,
      "loss": 0.1646,
      "step": 1450
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.2177734375,
      "learning_rate": 0.00027368421052631573,
      "loss": 0.1399,
      "step": 1500
    },
    {
      "epoch": 0.91,
      "grad_norm": 0.298828125,
      "learning_rate": 0.0002728070175438596,
      "loss": 0.1774,
      "step": 1550
    },
    {
      "epoch": 0.94,
      "grad_norm": 1.40625,
      "learning_rate": 0.0002719298245614035,
      "loss": 0.1517,
      "step": 1600
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.3203125,
      "learning_rate": 0.0002710526315789474,
      "loss": 0.1434,
      "step": 1650
    },
    {
      "epoch": 0.99,
      "grad_norm": 0.373046875,
      "learning_rate": 0.0002701754385964912,
      "loss": 0.1503,
      "step": 1700
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.1390799582004547,
      "eval_matthews_correlation": 0.5385674019281754,
      "eval_out_of_cls": 3422,
      "eval_runtime": 77.4928,
      "eval_samples_per_second": 22.079,
      "eval_steps_per_second": 22.079,
      "step": 1710
    },
    {
      "epoch": 1.02,
      "grad_norm": 0.46484375,
      "learning_rate": 0.00026929824561403503,
      "loss": 0.1149,
      "step": 1750
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.380859375,
      "learning_rate": 0.0002684210526315789,
      "loss": 0.1357,
      "step": 1800
    },
    {
      "epoch": 1.08,
      "grad_norm": 0.62890625,
      "learning_rate": 0.0002675438596491228,
      "loss": 0.1138,
      "step": 1850
    },
    {
      "epoch": 1.11,
      "grad_norm": 0.1767578125,
      "learning_rate": 0.0002666666666666666,
      "loss": 0.1362,
      "step": 1900
    },
    {
      "epoch": 1.14,
      "grad_norm": 0.9609375,
      "learning_rate": 0.0002657894736842105,
      "loss": 0.1087,
      "step": 1950
    },
    {
      "epoch": 1.17,
      "grad_norm": 0.490234375,
      "learning_rate": 0.0002649122807017544,
      "loss": 0.0834,
      "step": 2000
    },
    {
      "epoch": 1.2,
      "grad_norm": 1.1484375,
      "learning_rate": 0.0002640350877192982,
      "loss": 0.1067,
      "step": 2050
    },
    {
      "epoch": 1.23,
      "grad_norm": 0.1376953125,
      "learning_rate": 0.00026315789473684205,
      "loss": 0.112,
      "step": 2100
    },
    {
      "epoch": 1.26,
      "grad_norm": 0.6640625,
      "learning_rate": 0.00026228070175438593,
      "loss": 0.1244,
      "step": 2150
    },
    {
      "epoch": 1.29,
      "grad_norm": 0.376953125,
      "learning_rate": 0.0002614035087719298,
      "loss": 0.1362,
      "step": 2200
    },
    {
      "epoch": 1.32,
      "grad_norm": 0.74609375,
      "learning_rate": 0.0002605263157894737,
      "loss": 0.1209,
      "step": 2250
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.8203125,
      "learning_rate": 0.0002596491228070175,
      "loss": 0.1426,
      "step": 2300
    },
    {
      "epoch": 1.37,
      "grad_norm": 0.30859375,
      "learning_rate": 0.0002587719298245614,
      "loss": 0.1036,
      "step": 2350
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.216796875,
      "learning_rate": 0.00025789473684210523,
      "loss": 0.0933,
      "step": 2400
    },
    {
      "epoch": 1.43,
      "grad_norm": 0.494140625,
      "learning_rate": 0.0002570175438596491,
      "loss": 0.1161,
      "step": 2450
    },
    {
      "epoch": 1.46,
      "grad_norm": 0.1591796875,
      "learning_rate": 0.00025614035087719294,
      "loss": 0.1024,
      "step": 2500
    },
    {
      "epoch": 1.49,
      "grad_norm": 0.66015625,
      "learning_rate": 0.0002552631578947368,
      "loss": 0.1237,
      "step": 2550
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.2294921875,
      "learning_rate": 0.0002543859649122807,
      "loss": 0.0946,
      "step": 2600
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.93359375,
      "learning_rate": 0.00025350877192982453,
      "loss": 0.111,
      "step": 2650
    },
    {
      "epoch": 1.58,
      "grad_norm": 0.546875,
      "learning_rate": 0.00025263157894736836,
      "loss": 0.119,
      "step": 2700
    },
    {
      "epoch": 1.61,
      "grad_norm": 3.15625,
      "learning_rate": 0.00025175438596491224,
      "loss": 0.1226,
      "step": 2750
    },
    {
      "epoch": 1.64,
      "grad_norm": 0.0546875,
      "learning_rate": 0.0002508771929824561,
      "loss": 0.1039,
      "step": 2800
    },
    {
      "epoch": 1.67,
      "grad_norm": 0.33203125,
      "learning_rate": 0.00025,
      "loss": 0.1297,
      "step": 2850
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.2294921875,
      "learning_rate": 0.00024912280701754383,
      "loss": 0.122,
      "step": 2900
    },
    {
      "epoch": 1.73,
      "grad_norm": 0.859375,
      "learning_rate": 0.0002482456140350877,
      "loss": 0.09,
      "step": 2950
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.796875,
      "learning_rate": 0.00024736842105263154,
      "loss": 0.1069,
      "step": 3000
    },
    {
      "epoch": 1.78,
      "grad_norm": 0.92578125,
      "learning_rate": 0.0002464912280701754,
      "loss": 0.1141,
      "step": 3050
    },
    {
      "epoch": 1.81,
      "grad_norm": 1.015625,
      "learning_rate": 0.00024561403508771925,
      "loss": 0.0889,
      "step": 3100
    },
    {
      "epoch": 1.84,
      "grad_norm": 2.171875,
      "learning_rate": 0.00024473684210526314,
      "loss": 0.0949,
      "step": 3150
    },
    {
      "epoch": 1.87,
      "grad_norm": 0.427734375,
      "learning_rate": 0.000243859649122807,
      "loss": 0.0981,
      "step": 3200
    },
    {
      "epoch": 1.9,
      "grad_norm": 1.84375,
      "learning_rate": 0.00024298245614035087,
      "loss": 0.1059,
      "step": 3250
    },
    {
      "epoch": 1.93,
      "grad_norm": 0.1484375,
      "learning_rate": 0.0002421052631578947,
      "loss": 0.1238,
      "step": 3300
    },
    {
      "epoch": 1.96,
      "grad_norm": 0.5234375,
      "learning_rate": 0.00024122807017543858,
      "loss": 0.1283,
      "step": 3350
    },
    {
      "epoch": 1.99,
      "grad_norm": 0.263671875,
      "learning_rate": 0.00024035087719298244,
      "loss": 0.1178,
      "step": 3400
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.11864373087882996,
      "eval_matthews_correlation": 0.6287700364610441,
      "eval_out_of_cls": 3422,
      "eval_runtime": 81.2925,
      "eval_samples_per_second": 21.047,
      "eval_steps_per_second": 21.047,
      "step": 3420
    },
    {
      "epoch": 2.02,
      "grad_norm": 2.65625,
      "learning_rate": 0.00023947368421052632,
      "loss": 0.0948,
      "step": 3450
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.107421875,
      "learning_rate": 0.00023859649122807015,
      "loss": 0.0746,
      "step": 3500
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.96484375,
      "learning_rate": 0.000237719298245614,
      "loss": 0.0667,
      "step": 3550
    },
    {
      "epoch": 2.11,
      "grad_norm": 0.0849609375,
      "learning_rate": 0.00023684210526315788,
      "loss": 0.0614,
      "step": 3600
    },
    {
      "epoch": 2.13,
      "grad_norm": 0.38671875,
      "learning_rate": 0.00023596491228070174,
      "loss": 0.0554,
      "step": 3650
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.23828125,
      "learning_rate": 0.0002350877192982456,
      "loss": 0.074,
      "step": 3700
    },
    {
      "epoch": 2.19,
      "grad_norm": 1.1328125,
      "learning_rate": 0.00023421052631578945,
      "loss": 0.0811,
      "step": 3750
    },
    {
      "epoch": 2.22,
      "grad_norm": 0.984375,
      "learning_rate": 0.0002333333333333333,
      "loss": 0.0552,
      "step": 3800
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.337890625,
      "learning_rate": 0.00023245614035087719,
      "loss": 0.0613,
      "step": 3850
    },
    {
      "epoch": 2.28,
      "grad_norm": 1.96875,
      "learning_rate": 0.00023157894736842101,
      "loss": 0.0532,
      "step": 3900
    },
    {
      "epoch": 2.31,
      "grad_norm": 0.404296875,
      "learning_rate": 0.0002307017543859649,
      "loss": 0.0741,
      "step": 3950
    },
    {
      "epoch": 2.34,
      "grad_norm": 0.07275390625,
      "learning_rate": 0.00022982456140350875,
      "loss": 0.0583,
      "step": 4000
    },
    {
      "epoch": 2.37,
      "grad_norm": 0.035400390625,
      "learning_rate": 0.00022894736842105263,
      "loss": 0.07,
      "step": 4050
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.578125,
      "learning_rate": 0.00022807017543859646,
      "loss": 0.0643,
      "step": 4100
    },
    {
      "epoch": 2.43,
      "grad_norm": 0.07275390625,
      "learning_rate": 0.00022719298245614032,
      "loss": 0.0816,
      "step": 4150
    },
    {
      "epoch": 2.46,
      "grad_norm": 0.2236328125,
      "learning_rate": 0.0002263157894736842,
      "loss": 0.0617,
      "step": 4200
    },
    {
      "epoch": 2.49,
      "grad_norm": 1.8125,
      "learning_rate": 0.00022543859649122805,
      "loss": 0.1014,
      "step": 4250
    },
    {
      "epoch": 2.51,
      "grad_norm": 0.09814453125,
      "learning_rate": 0.0002245614035087719,
      "loss": 0.071,
      "step": 4300
    },
    {
      "epoch": 2.54,
      "grad_norm": 3.5625,
      "learning_rate": 0.00022368421052631576,
      "loss": 0.0414,
      "step": 4350
    },
    {
      "epoch": 2.57,
      "grad_norm": 1.203125,
      "learning_rate": 0.00022280701754385964,
      "loss": 0.0701,
      "step": 4400
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.0439453125,
      "learning_rate": 0.0002219298245614035,
      "loss": 0.0547,
      "step": 4450
    },
    {
      "epoch": 2.63,
      "grad_norm": 0.0673828125,
      "learning_rate": 0.00022105263157894733,
      "loss": 0.0551,
      "step": 4500
    },
    {
      "epoch": 2.66,
      "grad_norm": 0.047119140625,
      "learning_rate": 0.0002201754385964912,
      "loss": 0.0468,
      "step": 4550
    },
    {
      "epoch": 2.69,
      "grad_norm": 0.171875,
      "learning_rate": 0.00021929824561403506,
      "loss": 0.0535,
      "step": 4600
    },
    {
      "epoch": 2.72,
      "grad_norm": 0.53125,
      "learning_rate": 0.00021842105263157895,
      "loss": 0.0771,
      "step": 4650
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.1123046875,
      "learning_rate": 0.00021754385964912277,
      "loss": 0.0697,
      "step": 4700
    },
    {
      "epoch": 2.78,
      "grad_norm": 0.0458984375,
      "learning_rate": 0.00021666666666666666,
      "loss": 0.0378,
      "step": 4750
    },
    {
      "epoch": 2.81,
      "grad_norm": 2.359375,
      "learning_rate": 0.0002157894736842105,
      "loss": 0.0896,
      "step": 4800
    },
    {
      "epoch": 2.84,
      "grad_norm": 1.7578125,
      "learning_rate": 0.00021491228070175437,
      "loss": 0.0814,
      "step": 4850
    },
    {
      "epoch": 2.87,
      "grad_norm": 0.734375,
      "learning_rate": 0.00021403508771929822,
      "loss": 0.0642,
      "step": 4900
    },
    {
      "epoch": 2.89,
      "grad_norm": 0.69140625,
      "learning_rate": 0.00021315789473684208,
      "loss": 0.0775,
      "step": 4950
    },
    {
      "epoch": 2.92,
      "grad_norm": 0.349609375,
      "learning_rate": 0.00021228070175438596,
      "loss": 0.0793,
      "step": 5000
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.470703125,
      "learning_rate": 0.00021140350877192981,
      "loss": 0.0783,
      "step": 5050
    },
    {
      "epoch": 2.98,
      "grad_norm": 0.380859375,
      "learning_rate": 0.00021052631578947364,
      "loss": 0.0621,
      "step": 5100
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.13536684215068817,
      "eval_matthews_correlation": 0.6299050190315689,
      "eval_out_of_cls": 3422,
      "eval_runtime": 69.8258,
      "eval_samples_per_second": 24.504,
      "eval_steps_per_second": 24.504,
      "step": 5130
    },
    {
      "epoch": 3.01,
      "grad_norm": 0.0693359375,
      "learning_rate": 0.00020964912280701752,
      "loss": 0.0711,
      "step": 5150
    },
    {
      "epoch": 3.04,
      "grad_norm": 0.2177734375,
      "learning_rate": 0.00020877192982456138,
      "loss": 0.0267,
      "step": 5200
    },
    {
      "epoch": 3.07,
      "grad_norm": 0.06103515625,
      "learning_rate": 0.00020789473684210526,
      "loss": 0.0305,
      "step": 5250
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.0712890625,
      "learning_rate": 0.0002070175438596491,
      "loss": 0.0558,
      "step": 5300
    },
    {
      "epoch": 3.13,
      "grad_norm": 1.2734375,
      "learning_rate": 0.00020614035087719297,
      "loss": 0.0421,
      "step": 5350
    },
    {
      "epoch": 3.16,
      "grad_norm": 0.0177001953125,
      "learning_rate": 0.00020526315789473683,
      "loss": 0.0516,
      "step": 5400
    },
    {
      "epoch": 3.19,
      "grad_norm": 0.1865234375,
      "learning_rate": 0.0002043859649122807,
      "loss": 0.0322,
      "step": 5450
    },
    {
      "epoch": 3.22,
      "grad_norm": 0.020751953125,
      "learning_rate": 0.00020350877192982454,
      "loss": 0.0498,
      "step": 5500
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.12451171875,
      "learning_rate": 0.0002026315789473684,
      "loss": 0.0562,
      "step": 5550
    },
    {
      "epoch": 3.27,
      "grad_norm": 2.890625,
      "learning_rate": 0.00020175438596491227,
      "loss": 0.0326,
      "step": 5600
    },
    {
      "epoch": 3.3,
      "grad_norm": 2.3125,
      "learning_rate": 0.00020087719298245613,
      "loss": 0.0395,
      "step": 5650
    },
    {
      "epoch": 3.33,
      "grad_norm": 0.26171875,
      "learning_rate": 0.00019999999999999998,
      "loss": 0.0409,
      "step": 5700
    },
    {
      "epoch": 3.36,
      "grad_norm": 0.01513671875,
      "learning_rate": 0.00019912280701754384,
      "loss": 0.031,
      "step": 5750
    },
    {
      "epoch": 3.39,
      "grad_norm": 6.875,
      "learning_rate": 0.00019824561403508772,
      "loss": 0.0144,
      "step": 5800
    },
    {
      "epoch": 3.42,
      "grad_norm": 0.010009765625,
      "learning_rate": 0.00019736842105263157,
      "loss": 0.0373,
      "step": 5850
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.06689453125,
      "learning_rate": 0.0001964912280701754,
      "loss": 0.0293,
      "step": 5900
    },
    {
      "epoch": 3.48,
      "grad_norm": 0.369140625,
      "learning_rate": 0.00019561403508771928,
      "loss": 0.0241,
      "step": 5950
    },
    {
      "epoch": 3.51,
      "grad_norm": 0.023193359375,
      "learning_rate": 0.00019473684210526314,
      "loss": 0.0214,
      "step": 6000
    },
    {
      "epoch": 3.54,
      "grad_norm": 0.0294189453125,
      "learning_rate": 0.00019385964912280702,
      "loss": 0.0502,
      "step": 6050
    },
    {
      "epoch": 3.57,
      "grad_norm": 0.041015625,
      "learning_rate": 0.00019298245614035085,
      "loss": 0.0291,
      "step": 6100
    },
    {
      "epoch": 3.6,
      "grad_norm": 1.3203125,
      "learning_rate": 0.0001921052631578947,
      "loss": 0.0475,
      "step": 6150
    },
    {
      "epoch": 3.63,
      "grad_norm": 3.28125,
      "learning_rate": 0.00019122807017543859,
      "loss": 0.0342,
      "step": 6200
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.06103515625,
      "learning_rate": 0.00019035087719298244,
      "loss": 0.0366,
      "step": 6250
    },
    {
      "epoch": 3.68,
      "grad_norm": 0.0732421875,
      "learning_rate": 0.0001894736842105263,
      "loss": 0.0459,
      "step": 6300
    },
    {
      "epoch": 3.71,
      "grad_norm": 0.76171875,
      "learning_rate": 0.00018859649122807015,
      "loss": 0.0157,
      "step": 6350
    },
    {
      "epoch": 3.74,
      "grad_norm": 1.8203125,
      "learning_rate": 0.00018771929824561403,
      "loss": 0.0521,
      "step": 6400
    },
    {
      "epoch": 3.77,
      "grad_norm": 0.1025390625,
      "learning_rate": 0.0001868421052631579,
      "loss": 0.0416,
      "step": 6450
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.12451171875,
      "learning_rate": 0.00018596491228070172,
      "loss": 0.0345,
      "step": 6500
    },
    {
      "epoch": 3.83,
      "grad_norm": 0.11865234375,
      "learning_rate": 0.0001850877192982456,
      "loss": 0.0319,
      "step": 6550
    },
    {
      "epoch": 3.86,
      "grad_norm": 0.0284423828125,
      "learning_rate": 0.00018421052631578945,
      "loss": 0.0287,
      "step": 6600
    },
    {
      "epoch": 3.89,
      "grad_norm": 2.515625,
      "learning_rate": 0.00018333333333333334,
      "loss": 0.0394,
      "step": 6650
    },
    {
      "epoch": 3.92,
      "grad_norm": 0.03369140625,
      "learning_rate": 0.00018245614035087716,
      "loss": 0.0393,
      "step": 6700
    },
    {
      "epoch": 3.95,
      "grad_norm": 0.0361328125,
      "learning_rate": 0.00018157894736842105,
      "loss": 0.0535,
      "step": 6750
    },
    {
      "epoch": 3.98,
      "grad_norm": 0.031005859375,
      "learning_rate": 0.0001807017543859649,
      "loss": 0.0258,
      "step": 6800
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.1802884191274643,
      "eval_matthews_correlation": 0.6245963393574332,
      "eval_out_of_cls": 3422,
      "eval_runtime": 70.9084,
      "eval_samples_per_second": 24.13,
      "eval_steps_per_second": 24.13,
      "step": 6840
    },
    {
      "epoch": 4.01,
      "grad_norm": 0.34765625,
      "learning_rate": 0.00017982456140350878,
      "loss": 0.0373,
      "step": 6850
    },
    {
      "epoch": 4.04,
      "grad_norm": 0.37890625,
      "learning_rate": 0.0001789473684210526,
      "loss": 0.0216,
      "step": 6900
    },
    {
      "epoch": 4.06,
      "grad_norm": 0.0791015625,
      "learning_rate": 0.00017807017543859647,
      "loss": 0.0217,
      "step": 6950
    },
    {
      "epoch": 4.09,
      "grad_norm": 0.0224609375,
      "learning_rate": 0.00017719298245614035,
      "loss": 0.0123,
      "step": 7000
    },
    {
      "epoch": 4.12,
      "grad_norm": 0.0233154296875,
      "learning_rate": 0.0001763157894736842,
      "loss": 0.0189,
      "step": 7050
    },
    {
      "epoch": 4.15,
      "grad_norm": 0.07177734375,
      "learning_rate": 0.00017543859649122806,
      "loss": 0.0116,
      "step": 7100
    },
    {
      "epoch": 4.18,
      "grad_norm": 0.0213623046875,
      "learning_rate": 0.0001745614035087719,
      "loss": 0.0219,
      "step": 7150
    },
    {
      "epoch": 4.21,
      "grad_norm": 0.0301513671875,
      "learning_rate": 0.0001736842105263158,
      "loss": 0.0336,
      "step": 7200
    },
    {
      "epoch": 4.24,
      "grad_norm": 0.044921875,
      "learning_rate": 0.00017280701754385965,
      "loss": 0.0272,
      "step": 7250
    },
    {
      "epoch": 4.27,
      "grad_norm": 0.022216796875,
      "learning_rate": 0.00017192982456140348,
      "loss": 0.0107,
      "step": 7300
    },
    {
      "epoch": 4.3,
      "grad_norm": 2.921875,
      "learning_rate": 0.00017105263157894736,
      "loss": 0.0111,
      "step": 7350
    },
    {
      "epoch": 4.33,
      "grad_norm": 0.003936767578125,
      "learning_rate": 0.00017017543859649121,
      "loss": 0.0223,
      "step": 7400
    },
    {
      "epoch": 4.36,
      "grad_norm": 0.029296875,
      "learning_rate": 0.0001692982456140351,
      "loss": 0.0233,
      "step": 7450
    },
    {
      "epoch": 4.39,
      "grad_norm": 1.1015625,
      "learning_rate": 0.00016842105263157892,
      "loss": 0.0386,
      "step": 7500
    },
    {
      "epoch": 4.42,
      "grad_norm": 0.029052734375,
      "learning_rate": 0.00016754385964912278,
      "loss": 0.0197,
      "step": 7550
    },
    {
      "epoch": 4.44,
      "grad_norm": 0.0712890625,
      "learning_rate": 0.00016666666666666666,
      "loss": 0.0228,
      "step": 7600
    },
    {
      "epoch": 4.47,
      "grad_norm": 0.07958984375,
      "learning_rate": 0.00016578947368421052,
      "loss": 0.0137,
      "step": 7650
    },
    {
      "epoch": 4.5,
      "grad_norm": 0.13671875,
      "learning_rate": 0.00016491228070175437,
      "loss": 0.0186,
      "step": 7700
    },
    {
      "epoch": 4.53,
      "grad_norm": 0.023681640625,
      "learning_rate": 0.00016403508771929823,
      "loss": 0.0266,
      "step": 7750
    },
    {
      "epoch": 4.56,
      "grad_norm": 0.006317138671875,
      "learning_rate": 0.0001631578947368421,
      "loss": 0.0119,
      "step": 7800
    },
    {
      "epoch": 4.59,
      "grad_norm": 0.0072021484375,
      "learning_rate": 0.00016228070175438596,
      "loss": 0.0086,
      "step": 7850
    },
    {
      "epoch": 4.62,
      "grad_norm": 0.0498046875,
      "learning_rate": 0.0001614035087719298,
      "loss": 0.02,
      "step": 7900
    },
    {
      "epoch": 4.65,
      "grad_norm": 0.033935546875,
      "learning_rate": 0.00016052631578947367,
      "loss": 0.0355,
      "step": 7950
    },
    {
      "epoch": 4.68,
      "grad_norm": 0.039306640625,
      "learning_rate": 0.00015964912280701753,
      "loss": 0.0323,
      "step": 8000
    },
    {
      "epoch": 4.71,
      "grad_norm": 0.08154296875,
      "learning_rate": 0.0001587719298245614,
      "loss": 0.0314,
      "step": 8050
    },
    {
      "epoch": 4.74,
      "grad_norm": 0.123046875,
      "learning_rate": 0.00015789473684210524,
      "loss": 0.0296,
      "step": 8100
    },
    {
      "epoch": 4.77,
      "grad_norm": 0.036376953125,
      "learning_rate": 0.00015701754385964912,
      "loss": 0.0342,
      "step": 8150
    },
    {
      "epoch": 4.8,
      "grad_norm": 0.0634765625,
      "learning_rate": 0.00015614035087719297,
      "loss": 0.014,
      "step": 8200
    },
    {
      "epoch": 4.82,
      "grad_norm": 0.0189208984375,
      "learning_rate": 0.00015526315789473686,
      "loss": 0.0246,
      "step": 8250
    },
    {
      "epoch": 4.85,
      "grad_norm": 0.0230712890625,
      "learning_rate": 0.00015438596491228068,
      "loss": 0.0182,
      "step": 8300
    },
    {
      "epoch": 4.88,
      "grad_norm": 0.00616455078125,
      "learning_rate": 0.00015350877192982454,
      "loss": 0.0274,
      "step": 8350
    },
    {
      "epoch": 4.91,
      "grad_norm": 0.016845703125,
      "learning_rate": 0.00015263157894736842,
      "loss": 0.032,
      "step": 8400
    },
    {
      "epoch": 4.94,
      "grad_norm": 0.01953125,
      "learning_rate": 0.00015175438596491228,
      "loss": 0.0171,
      "step": 8450
    },
    {
      "epoch": 4.97,
      "grad_norm": 0.03857421875,
      "learning_rate": 0.00015087719298245613,
      "loss": 0.0107,
      "step": 8500
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.2734375,
      "learning_rate": 0.00015,
      "loss": 0.0229,
      "step": 8550
    },
    {
      "epoch": 5.0,
      "eval_loss": 0.24207192659378052,
      "eval_matthews_correlation": 0.6348242258280475,
      "eval_out_of_cls": 3422,
      "eval_runtime": 70.2942,
      "eval_samples_per_second": 24.341,
      "eval_steps_per_second": 24.341,
      "step": 8550
    },
    {
      "epoch": 5.03,
      "grad_norm": 0.0380859375,
      "learning_rate": 0.00014912280701754384,
      "loss": 0.0058,
      "step": 8600
    },
    {
      "epoch": 5.06,
      "grad_norm": 0.0673828125,
      "learning_rate": 0.0001482456140350877,
      "loss": 0.0037,
      "step": 8650
    },
    {
      "epoch": 5.09,
      "grad_norm": 0.047607421875,
      "learning_rate": 0.00014736842105263155,
      "loss": 0.028,
      "step": 8700
    },
    {
      "epoch": 5.12,
      "grad_norm": 0.01312255859375,
      "learning_rate": 0.00014649122807017543,
      "loss": 0.0116,
      "step": 8750
    },
    {
      "epoch": 5.15,
      "grad_norm": 0.15234375,
      "learning_rate": 0.0001456140350877193,
      "loss": 0.0051,
      "step": 8800
    },
    {
      "epoch": 5.18,
      "grad_norm": 0.0108642578125,
      "learning_rate": 0.00014473684210526314,
      "loss": 0.0142,
      "step": 8850
    },
    {
      "epoch": 5.2,
      "grad_norm": 0.05419921875,
      "learning_rate": 0.000143859649122807,
      "loss": 0.021,
      "step": 8900
    },
    {
      "epoch": 5.23,
      "grad_norm": 0.099609375,
      "learning_rate": 0.00014298245614035085,
      "loss": 0.0234,
      "step": 8950
    },
    {
      "epoch": 5.26,
      "grad_norm": 0.009521484375,
      "learning_rate": 0.0001421052631578947,
      "loss": 0.0008,
      "step": 9000
    },
    {
      "epoch": 5.29,
      "grad_norm": 0.00079345703125,
      "learning_rate": 0.0001412280701754386,
      "loss": 0.0106,
      "step": 9050
    },
    {
      "epoch": 5.32,
      "grad_norm": 0.008544921875,
      "learning_rate": 0.00014035087719298245,
      "loss": 0.0157,
      "step": 9100
    },
    {
      "epoch": 5.35,
      "grad_norm": 0.01287841796875,
      "learning_rate": 0.0001394736842105263,
      "loss": 0.019,
      "step": 9150
    },
    {
      "epoch": 5.38,
      "grad_norm": 0.08984375,
      "learning_rate": 0.00013859649122807016,
      "loss": 0.0032,
      "step": 9200
    },
    {
      "epoch": 5.41,
      "grad_norm": 0.0164794921875,
      "learning_rate": 0.000137719298245614,
      "loss": 0.0236,
      "step": 9250
    },
    {
      "epoch": 5.44,
      "grad_norm": 0.01190185546875,
      "learning_rate": 0.00013684210526315787,
      "loss": 0.0221,
      "step": 9300
    },
    {
      "epoch": 5.47,
      "grad_norm": 0.015869140625,
      "learning_rate": 0.00013596491228070175,
      "loss": 0.0064,
      "step": 9350
    },
    {
      "epoch": 5.5,
      "grad_norm": 0.0162353515625,
      "learning_rate": 0.0001350877192982456,
      "loss": 0.0098,
      "step": 9400
    },
    {
      "epoch": 5.53,
      "grad_norm": 0.035400390625,
      "learning_rate": 0.00013421052631578946,
      "loss": 0.0044,
      "step": 9450
    },
    {
      "epoch": 5.56,
      "grad_norm": 3.3125,
      "learning_rate": 0.0001333333333333333,
      "loss": 0.0308,
      "step": 9500
    },
    {
      "epoch": 5.58,
      "grad_norm": 0.023681640625,
      "learning_rate": 0.0001324561403508772,
      "loss": 0.02,
      "step": 9550
    },
    {
      "epoch": 5.61,
      "grad_norm": 0.0751953125,
      "learning_rate": 0.00013157894736842102,
      "loss": 0.0181,
      "step": 9600
    },
    {
      "epoch": 5.64,
      "grad_norm": 0.036376953125,
      "learning_rate": 0.0001307017543859649,
      "loss": 0.0127,
      "step": 9650
    },
    {
      "epoch": 5.67,
      "grad_norm": 0.0380859375,
      "learning_rate": 0.00012982456140350876,
      "loss": 0.0109,
      "step": 9700
    },
    {
      "epoch": 5.7,
      "grad_norm": 0.0028533935546875,
      "learning_rate": 0.00012894736842105261,
      "loss": 0.0133,
      "step": 9750
    },
    {
      "epoch": 5.73,
      "grad_norm": 0.01513671875,
      "learning_rate": 0.00012807017543859647,
      "loss": 0.0197,
      "step": 9800
    },
    {
      "epoch": 5.76,
      "grad_norm": 0.015625,
      "learning_rate": 0.00012719298245614035,
      "loss": 0.0172,
      "step": 9850
    },
    {
      "epoch": 5.79,
      "grad_norm": 0.02294921875,
      "learning_rate": 0.00012631578947368418,
      "loss": 0.0051,
      "step": 9900
    },
    {
      "epoch": 5.82,
      "grad_norm": 0.0106201171875,
      "learning_rate": 0.00012543859649122806,
      "loss": 0.0192,
      "step": 9950
    },
    {
      "epoch": 5.85,
      "grad_norm": 0.00927734375,
      "learning_rate": 0.00012456140350877192,
      "loss": 0.0184,
      "step": 10000
    },
    {
      "epoch": 5.88,
      "grad_norm": 3.46875,
      "learning_rate": 0.00012368421052631577,
      "loss": 0.0304,
      "step": 10050
    },
    {
      "epoch": 5.91,
      "grad_norm": 0.004913330078125,
      "learning_rate": 0.00012280701754385963,
      "loss": 0.025,
      "step": 10100
    },
    {
      "epoch": 5.94,
      "grad_norm": 0.04638671875,
      "learning_rate": 0.0001219298245614035,
      "loss": 0.0137,
      "step": 10150
    },
    {
      "epoch": 5.96,
      "grad_norm": 0.0302734375,
      "learning_rate": 0.00012105263157894735,
      "loss": 0.0228,
      "step": 10200
    },
    {
      "epoch": 5.99,
      "grad_norm": 0.015380859375,
      "learning_rate": 0.00012017543859649122,
      "loss": 0.0066,
      "step": 10250
    },
    {
      "epoch": 6.0,
      "eval_loss": 0.2808413803577423,
      "eval_matthews_correlation": 0.621325231307334,
      "eval_out_of_cls": 3422,
      "eval_runtime": 69.1845,
      "eval_samples_per_second": 24.731,
      "eval_steps_per_second": 24.731,
      "step": 10260
    },
    {
      "epoch": 6.02,
      "grad_norm": 0.0042724609375,
      "learning_rate": 0.00011929824561403507,
      "loss": 0.0055,
      "step": 10300
    },
    {
      "epoch": 6.05,
      "grad_norm": 0.09521484375,
      "learning_rate": 0.00011842105263157894,
      "loss": 0.0103,
      "step": 10350
    },
    {
      "epoch": 6.08,
      "grad_norm": 0.0294189453125,
      "learning_rate": 0.0001175438596491228,
      "loss": 0.019,
      "step": 10400
    },
    {
      "epoch": 6.11,
      "grad_norm": 0.00958251953125,
      "learning_rate": 0.00011666666666666665,
      "loss": 0.0147,
      "step": 10450
    },
    {
      "epoch": 6.14,
      "grad_norm": 0.006744384765625,
      "learning_rate": 0.00011578947368421051,
      "loss": 0.0029,
      "step": 10500
    },
    {
      "epoch": 6.17,
      "grad_norm": 0.009033203125,
      "learning_rate": 0.00011491228070175438,
      "loss": 0.0094,
      "step": 10550
    },
    {
      "epoch": 6.2,
      "grad_norm": 0.032470703125,
      "learning_rate": 0.00011403508771929823,
      "loss": 0.016,
      "step": 10600
    },
    {
      "epoch": 6.23,
      "grad_norm": 1.140625,
      "learning_rate": 0.0001131578947368421,
      "loss": 0.0135,
      "step": 10650
    },
    {
      "epoch": 6.26,
      "grad_norm": 0.0091552734375,
      "learning_rate": 0.00011228070175438595,
      "loss": 0.0169,
      "step": 10700
    },
    {
      "epoch": 6.29,
      "grad_norm": 0.00787353515625,
      "learning_rate": 0.00011140350877192982,
      "loss": 0.0016,
      "step": 10750
    },
    {
      "epoch": 6.32,
      "grad_norm": 0.011962890625,
      "learning_rate": 0.00011052631578947366,
      "loss": 0.0034,
      "step": 10800
    },
    {
      "epoch": 6.35,
      "grad_norm": 0.00909423828125,
      "learning_rate": 0.00010964912280701753,
      "loss": 0.027,
      "step": 10850
    },
    {
      "epoch": 6.37,
      "grad_norm": 0.01458740234375,
      "learning_rate": 0.00010877192982456139,
      "loss": 0.0157,
      "step": 10900
    },
    {
      "epoch": 6.4,
      "grad_norm": 0.01031494140625,
      "learning_rate": 0.00010789473684210526,
      "loss": 0.0069,
      "step": 10950
    },
    {
      "epoch": 6.43,
      "grad_norm": 0.01397705078125,
      "learning_rate": 0.00010701754385964911,
      "loss": 0.0097,
      "step": 11000
    },
    {
      "epoch": 6.46,
      "grad_norm": 0.004913330078125,
      "learning_rate": 0.00010614035087719298,
      "loss": 0.0303,
      "step": 11050
    },
    {
      "epoch": 6.49,
      "grad_norm": 0.0299072265625,
      "learning_rate": 0.00010526315789473682,
      "loss": 0.0049,
      "step": 11100
    },
    {
      "epoch": 6.52,
      "grad_norm": 0.0185546875,
      "learning_rate": 0.00010438596491228069,
      "loss": 0.0145,
      "step": 11150
    },
    {
      "epoch": 6.55,
      "grad_norm": 0.0712890625,
      "learning_rate": 0.00010350877192982454,
      "loss": 0.0008,
      "step": 11200
    },
    {
      "epoch": 6.58,
      "grad_norm": 0.00390625,
      "learning_rate": 0.00010263157894736841,
      "loss": 0.0015,
      "step": 11250
    },
    {
      "epoch": 6.61,
      "grad_norm": 0.01123046875,
      "learning_rate": 0.00010175438596491227,
      "loss": 0.0227,
      "step": 11300
    },
    {
      "epoch": 6.64,
      "grad_norm": 0.0081787109375,
      "learning_rate": 0.00010087719298245614,
      "loss": 0.0143,
      "step": 11350
    },
    {
      "epoch": 6.67,
      "grad_norm": 0.0213623046875,
      "learning_rate": 9.999999999999999e-05,
      "loss": 0.0026,
      "step": 11400
    },
    {
      "epoch": 6.7,
      "grad_norm": 0.0166015625,
      "learning_rate": 9.912280701754386e-05,
      "loss": 0.0055,
      "step": 11450
    },
    {
      "epoch": 6.73,
      "grad_norm": 0.00860595703125,
      "learning_rate": 9.82456140350877e-05,
      "loss": 0.0111,
      "step": 11500
    },
    {
      "epoch": 6.75,
      "grad_norm": 0.000881195068359375,
      "learning_rate": 9.736842105263157e-05,
      "loss": 0.0138,
      "step": 11550
    },
    {
      "epoch": 6.78,
      "grad_norm": 0.01544189453125,
      "learning_rate": 9.649122807017542e-05,
      "loss": 0.0143,
      "step": 11600
    },
    {
      "epoch": 6.81,
      "grad_norm": 0.020751953125,
      "learning_rate": 9.561403508771929e-05,
      "loss": 0.0075,
      "step": 11650
    },
    {
      "epoch": 6.84,
      "grad_norm": 0.384765625,
      "learning_rate": 9.473684210526315e-05,
      "loss": 0.0063,
      "step": 11700
    },
    {
      "epoch": 6.87,
      "grad_norm": 0.0291748046875,
      "learning_rate": 9.385964912280702e-05,
      "loss": 0.0115,
      "step": 11750
    },
    {
      "epoch": 6.9,
      "grad_norm": 0.0038909912109375,
      "learning_rate": 9.298245614035086e-05,
      "loss": 0.0043,
      "step": 11800
    },
    {
      "epoch": 6.93,
      "grad_norm": 0.0361328125,
      "learning_rate": 9.210526315789473e-05,
      "loss": 0.0068,
      "step": 11850
    },
    {
      "epoch": 6.96,
      "grad_norm": 0.0224609375,
      "learning_rate": 9.122807017543858e-05,
      "loss": 0.0082,
      "step": 11900
    },
    {
      "epoch": 6.99,
      "grad_norm": 0.0035247802734375,
      "learning_rate": 9.035087719298245e-05,
      "loss": 0.0074,
      "step": 11950
    },
    {
      "epoch": 7.0,
      "eval_loss": 0.3440139889717102,
      "eval_matthews_correlation": 0.6092013145886174,
      "eval_out_of_cls": 3422,
      "eval_runtime": 71.1621,
      "eval_samples_per_second": 24.044,
      "eval_steps_per_second": 24.044,
      "step": 11970
    },
    {
      "epoch": 7.02,
      "grad_norm": 0.009521484375,
      "learning_rate": 8.94736842105263e-05,
      "loss": 0.0273,
      "step": 12000
    },
    {
      "epoch": 7.05,
      "grad_norm": 0.021728515625,
      "learning_rate": 8.859649122807017e-05,
      "loss": 0.0038,
      "step": 12050
    },
    {
      "epoch": 7.08,
      "grad_norm": 0.006561279296875,
      "learning_rate": 8.771929824561403e-05,
      "loss": 0.0043,
      "step": 12100
    },
    {
      "epoch": 7.11,
      "grad_norm": 1.6015625,
      "learning_rate": 8.68421052631579e-05,
      "loss": 0.0084,
      "step": 12150
    },
    {
      "epoch": 7.13,
      "grad_norm": 0.0263671875,
      "learning_rate": 8.596491228070174e-05,
      "loss": 0.0084,
      "step": 12200
    },
    {
      "epoch": 7.16,
      "grad_norm": 0.00083160400390625,
      "learning_rate": 8.508771929824561e-05,
      "loss": 0.0006,
      "step": 12250
    },
    {
      "epoch": 7.19,
      "grad_norm": 0.004364013671875,
      "learning_rate": 8.421052631578946e-05,
      "loss": 0.013,
      "step": 12300
    },
    {
      "epoch": 7.22,
      "grad_norm": 0.0205078125,
      "learning_rate": 8.333333333333333e-05,
      "loss": 0.01,
      "step": 12350
    },
    {
      "epoch": 7.25,
      "grad_norm": 0.05712890625,
      "learning_rate": 8.245614035087719e-05,
      "loss": 0.003,
      "step": 12400
    },
    {
      "epoch": 7.28,
      "grad_norm": 0.0011749267578125,
      "learning_rate": 8.157894736842105e-05,
      "loss": 0.0065,
      "step": 12450
    },
    {
      "epoch": 7.31,
      "grad_norm": 0.02978515625,
      "learning_rate": 8.07017543859649e-05,
      "loss": 0.0012,
      "step": 12500
    },
    {
      "epoch": 7.34,
      "grad_norm": 0.0029296875,
      "learning_rate": 7.982456140350876e-05,
      "loss": 0.0008,
      "step": 12550
    },
    {
      "epoch": 7.37,
      "grad_norm": 0.00787353515625,
      "learning_rate": 7.894736842105262e-05,
      "loss": 0.0021,
      "step": 12600
    },
    {
      "epoch": 7.4,
      "grad_norm": 0.0255126953125,
      "learning_rate": 7.807017543859649e-05,
      "loss": 0.0099,
      "step": 12650
    },
    {
      "epoch": 7.43,
      "grad_norm": 0.1484375,
      "learning_rate": 7.719298245614034e-05,
      "loss": 0.007,
      "step": 12700
    },
    {
      "epoch": 7.46,
      "grad_norm": 0.050048828125,
      "learning_rate": 7.631578947368421e-05,
      "loss": 0.006,
      "step": 12750
    },
    {
      "epoch": 7.49,
      "grad_norm": 0.0035552978515625,
      "learning_rate": 7.543859649122807e-05,
      "loss": 0.018,
      "step": 12800
    },
    {
      "epoch": 7.51,
      "grad_norm": 6.78125,
      "learning_rate": 7.456140350877192e-05,
      "loss": 0.0078,
      "step": 12850
    },
    {
      "epoch": 7.54,
      "grad_norm": 0.01953125,
      "learning_rate": 7.368421052631578e-05,
      "loss": 0.0026,
      "step": 12900
    },
    {
      "epoch": 7.57,
      "grad_norm": 0.005706787109375,
      "learning_rate": 7.280701754385964e-05,
      "loss": 0.0105,
      "step": 12950
    },
    {
      "epoch": 7.6,
      "grad_norm": 1.0,
      "learning_rate": 7.19298245614035e-05,
      "loss": 0.01,
      "step": 13000
    },
    {
      "epoch": 7.63,
      "grad_norm": 0.00176239013671875,
      "learning_rate": 7.105263157894735e-05,
      "loss": 0.0007,
      "step": 13050
    },
    {
      "epoch": 7.66,
      "grad_norm": 0.068359375,
      "learning_rate": 7.017543859649122e-05,
      "loss": 0.0093,
      "step": 13100
    },
    {
      "epoch": 7.69,
      "grad_norm": 0.007659912109375,
      "learning_rate": 6.929824561403508e-05,
      "loss": 0.0081,
      "step": 13150
    },
    {
      "epoch": 7.72,
      "grad_norm": 0.004058837890625,
      "learning_rate": 6.842105263157893e-05,
      "loss": 0.0122,
      "step": 13200
    },
    {
      "epoch": 7.75,
      "grad_norm": 0.11083984375,
      "learning_rate": 6.75438596491228e-05,
      "loss": 0.0257,
      "step": 13250
    },
    {
      "epoch": 7.78,
      "grad_norm": 0.00067138671875,
      "learning_rate": 6.666666666666666e-05,
      "loss": 0.0058,
      "step": 13300
    },
    {
      "epoch": 7.81,
      "grad_norm": 0.01385498046875,
      "learning_rate": 6.578947368421051e-05,
      "loss": 0.0038,
      "step": 13350
    },
    {
      "epoch": 7.84,
      "grad_norm": 0.0023956298828125,
      "learning_rate": 6.491228070175438e-05,
      "loss": 0.0026,
      "step": 13400
    },
    {
      "epoch": 7.87,
      "grad_norm": 0.0213623046875,
      "learning_rate": 6.403508771929823e-05,
      "loss": 0.0045,
      "step": 13450
    },
    {
      "epoch": 7.89,
      "grad_norm": 0.02685546875,
      "learning_rate": 6.315789473684209e-05,
      "loss": 0.0147,
      "step": 13500
    },
    {
      "epoch": 7.92,
      "grad_norm": 1.1015625,
      "learning_rate": 6.228070175438596e-05,
      "loss": 0.0053,
      "step": 13550
    },
    {
      "epoch": 7.95,
      "grad_norm": 0.00141143798828125,
      "learning_rate": 6.140350877192981e-05,
      "loss": 0.0105,
      "step": 13600
    },
    {
      "epoch": 7.98,
      "grad_norm": 0.0007171630859375,
      "learning_rate": 6.0526315789473675e-05,
      "loss": 0.0152,
      "step": 13650
    },
    {
      "epoch": 8.0,
      "eval_loss": 0.3466545045375824,
      "eval_matthews_correlation": 0.6160639005287759,
      "eval_out_of_cls": 3422,
      "eval_runtime": 69.6087,
      "eval_samples_per_second": 24.58,
      "eval_steps_per_second": 24.58,
      "step": 13680
    },
    {
      "epoch": 8.01,
      "grad_norm": 0.03515625,
      "learning_rate": 5.964912280701754e-05,
      "loss": 0.0023,
      "step": 13700
    },
    {
      "epoch": 8.04,
      "grad_norm": 0.0194091796875,
      "learning_rate": 5.87719298245614e-05,
      "loss": 0.0012,
      "step": 13750
    },
    {
      "epoch": 8.07,
      "grad_norm": 0.0147705078125,
      "learning_rate": 5.7894736842105253e-05,
      "loss": 0.0045,
      "step": 13800
    },
    {
      "epoch": 8.1,
      "grad_norm": 0.408203125,
      "learning_rate": 5.7017543859649115e-05,
      "loss": 0.0013,
      "step": 13850
    },
    {
      "epoch": 8.13,
      "grad_norm": 0.01513671875,
      "learning_rate": 5.614035087719298e-05,
      "loss": 0.0233,
      "step": 13900
    },
    {
      "epoch": 8.16,
      "grad_norm": 0.06640625,
      "learning_rate": 5.526315789473683e-05,
      "loss": 0.0008,
      "step": 13950
    },
    {
      "epoch": 8.19,
      "grad_norm": 0.162109375,
      "learning_rate": 5.4385964912280694e-05,
      "loss": 0.0095,
      "step": 14000
    },
    {
      "epoch": 8.22,
      "grad_norm": 0.00408935546875,
      "learning_rate": 5.3508771929824555e-05,
      "loss": 0.0101,
      "step": 14050
    },
    {
      "epoch": 8.25,
      "grad_norm": 0.064453125,
      "learning_rate": 5.263157894736841e-05,
      "loss": 0.0051,
      "step": 14100
    },
    {
      "epoch": 8.27,
      "grad_norm": 0.0252685546875,
      "learning_rate": 5.175438596491227e-05,
      "loss": 0.0153,
      "step": 14150
    },
    {
      "epoch": 8.3,
      "grad_norm": 0.00653076171875,
      "learning_rate": 5.0877192982456134e-05,
      "loss": 0.0027,
      "step": 14200
    },
    {
      "epoch": 8.33,
      "grad_norm": 0.00396728515625,
      "learning_rate": 4.9999999999999996e-05,
      "loss": 0.0012,
      "step": 14250
    },
    {
      "epoch": 8.36,
      "grad_norm": 0.00119781494140625,
      "learning_rate": 4.912280701754385e-05,
      "loss": 0.0054,
      "step": 14300
    },
    {
      "epoch": 8.39,
      "grad_norm": 0.004638671875,
      "learning_rate": 4.824561403508771e-05,
      "loss": 0.0083,
      "step": 14350
    },
    {
      "epoch": 8.42,
      "grad_norm": 0.0015716552734375,
      "learning_rate": 4.7368421052631574e-05,
      "loss": 0.0037,
      "step": 14400
    },
    {
      "epoch": 8.45,
      "grad_norm": 0.0223388671875,
      "learning_rate": 4.649122807017543e-05,
      "loss": 0.0009,
      "step": 14450
    },
    {
      "epoch": 8.48,
      "grad_norm": 0.0439453125,
      "learning_rate": 4.561403508771929e-05,
      "loss": 0.001,
      "step": 14500
    },
    {
      "epoch": 8.51,
      "grad_norm": 6.78125,
      "learning_rate": 4.473684210526315e-05,
      "loss": 0.0131,
      "step": 14550
    },
    {
      "epoch": 8.54,
      "grad_norm": 0.00074005126953125,
      "learning_rate": 4.3859649122807014e-05,
      "loss": 0.0044,
      "step": 14600
    },
    {
      "epoch": 8.57,
      "grad_norm": 0.04833984375,
      "learning_rate": 4.298245614035087e-05,
      "loss": 0.017,
      "step": 14650
    },
    {
      "epoch": 8.6,
      "grad_norm": 0.04248046875,
      "learning_rate": 4.210526315789473e-05,
      "loss": 0.0052,
      "step": 14700
    },
    {
      "epoch": 8.63,
      "grad_norm": 0.08447265625,
      "learning_rate": 4.122807017543859e-05,
      "loss": 0.0036,
      "step": 14750
    },
    {
      "epoch": 8.65,
      "grad_norm": 0.00141143798828125,
      "learning_rate": 4.035087719298245e-05,
      "loss": 0.0272,
      "step": 14800
    },
    {
      "epoch": 8.68,
      "grad_norm": 0.10302734375,
      "learning_rate": 3.947368421052631e-05,
      "loss": 0.0126,
      "step": 14850
    },
    {
      "epoch": 8.71,
      "grad_norm": 0.04345703125,
      "learning_rate": 3.859649122807017e-05,
      "loss": 0.0015,
      "step": 14900
    },
    {
      "epoch": 8.74,
      "grad_norm": 0.0322265625,
      "learning_rate": 3.771929824561403e-05,
      "loss": 0.0024,
      "step": 14950
    },
    {
      "epoch": 8.77,
      "grad_norm": 0.0120849609375,
      "learning_rate": 3.684210526315789e-05,
      "loss": 0.0082,
      "step": 15000
    },
    {
      "epoch": 8.8,
      "grad_norm": 0.052734375,
      "learning_rate": 3.596491228070175e-05,
      "loss": 0.0014,
      "step": 15050
    },
    {
      "epoch": 8.83,
      "grad_norm": 0.0035552978515625,
      "learning_rate": 3.508771929824561e-05,
      "loss": 0.0045,
      "step": 15100
    },
    {
      "epoch": 8.86,
      "grad_norm": 0.017822265625,
      "learning_rate": 3.4210526315789466e-05,
      "loss": 0.0055,
      "step": 15150
    },
    {
      "epoch": 8.89,
      "grad_norm": 6.34375,
      "learning_rate": 3.333333333333333e-05,
      "loss": 0.0105,
      "step": 15200
    },
    {
      "epoch": 8.92,
      "grad_norm": 0.041259765625,
      "learning_rate": 3.245614035087719e-05,
      "loss": 0.0006,
      "step": 15250
    },
    {
      "epoch": 8.95,
      "grad_norm": 0.0223388671875,
      "learning_rate": 3.1578947368421045e-05,
      "loss": 0.0032,
      "step": 15300
    },
    {
      "epoch": 8.98,
      "grad_norm": 0.0255126953125,
      "learning_rate": 3.070175438596491e-05,
      "loss": 0.0129,
      "step": 15350
    },
    {
      "epoch": 9.0,
      "eval_loss": 0.3481520116329193,
      "eval_matthews_correlation": 0.622532726437896,
      "eval_out_of_cls": 3422,
      "eval_runtime": 70.7453,
      "eval_samples_per_second": 24.185,
      "eval_steps_per_second": 24.185,
      "step": 15390
    },
    {
      "epoch": 9.01,
      "grad_norm": 0.0191650390625,
      "learning_rate": 2.982456140350877e-05,
      "loss": 0.0071,
      "step": 15400
    },
    {
      "epoch": 9.04,
      "grad_norm": 0.043701171875,
      "learning_rate": 2.8947368421052627e-05,
      "loss": 0.0084,
      "step": 15450
    },
    {
      "epoch": 9.06,
      "grad_norm": 0.0294189453125,
      "learning_rate": 2.807017543859649e-05,
      "loss": 0.0102,
      "step": 15500
    },
    {
      "epoch": 9.09,
      "grad_norm": 0.2490234375,
      "learning_rate": 2.7192982456140347e-05,
      "loss": 0.0074,
      "step": 15550
    },
    {
      "epoch": 9.12,
      "grad_norm": 0.0133056640625,
      "learning_rate": 2.6315789473684205e-05,
      "loss": 0.0065,
      "step": 15600
    },
    {
      "epoch": 9.15,
      "grad_norm": 0.023193359375,
      "learning_rate": 2.5438596491228067e-05,
      "loss": 0.0081,
      "step": 15650
    },
    {
      "epoch": 9.18,
      "grad_norm": 0.0206298828125,
      "learning_rate": 2.4561403508771925e-05,
      "loss": 0.0046,
      "step": 15700
    },
    {
      "epoch": 9.21,
      "grad_norm": 0.0174560546875,
      "learning_rate": 2.3684210526315787e-05,
      "loss": 0.0013,
      "step": 15750
    },
    {
      "epoch": 9.24,
      "grad_norm": 0.2451171875,
      "learning_rate": 2.2807017543859645e-05,
      "loss": 0.0009,
      "step": 15800
    },
    {
      "epoch": 9.27,
      "grad_norm": 0.01318359375,
      "learning_rate": 2.1929824561403507e-05,
      "loss": 0.0043,
      "step": 15850
    },
    {
      "epoch": 9.3,
      "grad_norm": 3.28125,
      "learning_rate": 2.1052631578947366e-05,
      "loss": 0.0068,
      "step": 15900
    },
    {
      "epoch": 9.33,
      "grad_norm": 6.5,
      "learning_rate": 2.0175438596491224e-05,
      "loss": 0.0076,
      "step": 15950
    },
    {
      "epoch": 9.36,
      "grad_norm": 8.25,
      "learning_rate": 1.9298245614035086e-05,
      "loss": 0.0033,
      "step": 16000
    },
    {
      "epoch": 9.39,
      "grad_norm": 0.058837890625,
      "learning_rate": 1.8421052631578944e-05,
      "loss": 0.004,
      "step": 16050
    },
    {
      "epoch": 9.42,
      "grad_norm": 1.015625,
      "learning_rate": 1.7543859649122806e-05,
      "loss": 0.0054,
      "step": 16100
    },
    {
      "epoch": 9.44,
      "grad_norm": 0.0234375,
      "learning_rate": 1.6666666666666664e-05,
      "loss": 0.0025,
      "step": 16150
    },
    {
      "epoch": 9.47,
      "grad_norm": 0.0272216796875,
      "learning_rate": 1.5789473684210522e-05,
      "loss": 0.008,
      "step": 16200
    },
    {
      "epoch": 9.5,
      "grad_norm": 0.00125885009765625,
      "learning_rate": 1.4912280701754384e-05,
      "loss": 0.022,
      "step": 16250
    },
    {
      "epoch": 9.53,
      "grad_norm": 0.054931640625,
      "learning_rate": 1.4035087719298244e-05,
      "loss": 0.0106,
      "step": 16300
    },
    {
      "epoch": 9.56,
      "grad_norm": 0.0081787109375,
      "learning_rate": 1.3157894736842103e-05,
      "loss": 0.003,
      "step": 16350
    },
    {
      "epoch": 9.59,
      "grad_norm": 0.01458740234375,
      "learning_rate": 1.2280701754385963e-05,
      "loss": 0.0094,
      "step": 16400
    },
    {
      "epoch": 9.62,
      "grad_norm": 0.029052734375,
      "learning_rate": 1.1403508771929823e-05,
      "loss": 0.0041,
      "step": 16450
    },
    {
      "epoch": 9.65,
      "grad_norm": 0.00634765625,
      "learning_rate": 1.0526315789473683e-05,
      "loss": 0.0108,
      "step": 16500
    },
    {
      "epoch": 9.68,
      "grad_norm": 0.004791259765625,
      "learning_rate": 9.649122807017543e-06,
      "loss": 0.002,
      "step": 16550
    },
    {
      "epoch": 9.71,
      "grad_norm": 0.02490234375,
      "learning_rate": 8.771929824561403e-06,
      "loss": 0.0089,
      "step": 16600
    },
    {
      "epoch": 9.74,
      "grad_norm": 0.1484375,
      "learning_rate": 7.894736842105261e-06,
      "loss": 0.0051,
      "step": 16650
    },
    {
      "epoch": 9.77,
      "grad_norm": 0.0034027099609375,
      "learning_rate": 7.017543859649122e-06,
      "loss": 0.0013,
      "step": 16700
    },
    {
      "epoch": 9.8,
      "grad_norm": 0.01177978515625,
      "learning_rate": 6.140350877192981e-06,
      "loss": 0.0007,
      "step": 16750
    },
    {
      "epoch": 9.82,
      "grad_norm": 0.0120849609375,
      "learning_rate": 5.263157894736841e-06,
      "loss": 0.0038,
      "step": 16800
    },
    {
      "epoch": 9.85,
      "grad_norm": 0.0732421875,
      "learning_rate": 4.3859649122807014e-06,
      "loss": 0.0129,
      "step": 16850
    },
    {
      "epoch": 9.88,
      "grad_norm": 0.0023956298828125,
      "learning_rate": 3.508771929824561e-06,
      "loss": 0.008,
      "step": 16900
    },
    {
      "epoch": 9.91,
      "grad_norm": 0.04150390625,
      "learning_rate": 2.6315789473684207e-06,
      "loss": 0.0008,
      "step": 16950
    },
    {
      "epoch": 9.94,
      "grad_norm": 0.031982421875,
      "learning_rate": 1.7543859649122805e-06,
      "loss": 0.0052,
      "step": 17000
    },
    {
      "epoch": 9.97,
      "grad_norm": 0.041259765625,
      "learning_rate": 8.771929824561403e-07,
      "loss": 0.0148,
      "step": 17050
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.010986328125,
      "learning_rate": 0.0,
      "loss": 0.0065,
      "step": 17100
    },
    {
      "epoch": 10.0,
      "eval_loss": 0.3472973108291626,
      "eval_matthews_correlation": 0.6220926310443936,
      "eval_out_of_cls": 3422,
      "eval_runtime": 67.3706,
      "eval_samples_per_second": 25.397,
      "eval_steps_per_second": 25.397,
      "step": 17100
    }
  ],
  "logging_steps": 50,
  "max_steps": 17100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 1710,
  "total_flos": 3.033191781634867e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
