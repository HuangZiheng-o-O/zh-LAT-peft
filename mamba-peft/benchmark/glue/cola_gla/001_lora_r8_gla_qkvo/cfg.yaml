backend: cuda
batch_size: 4
cfg_path: /home/user/mzs_h/code/zh-ssm-peft/mamba-peft/cfg/exps/benchmark/glue/cola_gla/001_lora_r8_gla_qkvo.yaml
data: glue-tvt_cola
debug: false
eval_epochs: 1
eval_gen: null
gradient_accumulation_steps: 1
is_sdlora: false
learning_rate: 0.001
lock: false
min_eval_metric_after_epoch: null
model: /home/user/mzs_h/model/second-gla-1.3B-100B/gla-1.3B-100B
no_save: false
num_data_workers: 8
num_epochs: 10
optim: adamw_torch
output_dir: /home/user/mzs_h/code/zh-ssm-peft/mamba-peft/benchmark/glue/cola_gla/001_lora_r8_gla_qkvo
overwrite: false
peft: cfg/peft/lora/r8/lora_gla_qkvo.json
prec: bf16
resume: false
seed: 42
skip_eval: false
tokenizer: EleutherAI/gpt-neox-20b
val_data: null
val_data_split: val
