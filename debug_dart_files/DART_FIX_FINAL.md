# DART è®­ç»ƒä¿®å¤ - æœ€ç»ˆè§£å†³æ–¹æ¡ˆ

## ğŸ¯ é—®é¢˜æ ¹æº

ç»è¿‡æ·±å…¥è°ƒè¯•ï¼Œæ‰¾åˆ°äº†çœŸæ­£çš„é—®é¢˜ï¼š

**pandas çš„ `to_pandas()` æ–¹æ³•ä¼šå°† HF Dataset ä¸­çš„ `list` ç±»å‹å­—æ®µè½¬æ¢ä¸º `numpy.ndarray`ï¼Œä½† `dart_data.py` ä¸­çš„ `build_lists` å‡½æ•°åªæ£€æŸ¥ `isinstance(ann, list)`ï¼Œå¯¼è‡´æ‰€æœ‰æ•°æ®è¢«è·³è¿‡ï¼Œæœ€ç»ˆè¿”å›ç©º DataFrameã€‚**

### è°ƒè¯•è¿‡ç¨‹

1. **åˆå§‹ç°è±¡**ï¼šè®­ç»ƒæ—¶æŠ¥ `num_samples=0`
2. **ç¬¬ä¸€æ¬¡è°ƒè¯•**ï¼šå‘ç°å¹¶è¡Œå¤„ç†æ²¡æœ‰é”™è¯¯è¾“å‡ºï¼Œæ€€ç–‘æ˜¯ç¼“å­˜é—®é¢˜
3. **ç¬¬äºŒæ¬¡è°ƒè¯•**ï¼šæ¸…ç†ç¼“å­˜åï¼Œå‘ç° `load_df()` è¿”å› 0 è¡Œ
4. **ç¬¬ä¸‰æ¬¡è°ƒè¯•**ï¼šæ‰‹åŠ¨æµ‹è¯• `build_lists` é€»è¾‘ï¼Œå‘ç°è¿”å›ç©ºå­—ç¬¦ä¸²
5. **ç¬¬å››æ¬¡è°ƒè¯•**ï¼šå¯¹æ¯”ä¸¤ç§åŠ è½½æ–¹å¼ï¼Œå‘ç° `annotations` æ˜¯ `numpy.ndarray` è€Œä¸æ˜¯ `list`
6. **æœ€ç»ˆå®šä½**ï¼š`isinstance(ann, list)` æ£€æŸ¥å¤±è´¥ï¼Œå¯¼è‡´æ•°æ®è¢«è·³è¿‡

## âœ… ä¿®å¤æ–¹æ¡ˆ

### ä¿®æ”¹æ–‡ä»¶ï¼š`mamba-peft/dataset/dart_data.py`

**ç¬¬ 183 è¡Œ**ï¼Œå°†ï¼š
```python
if isinstance(ann, list):
```

æ”¹ä¸ºï¼š
```python
if isinstance(ann, (list, np.ndarray)):
```

è¿™æ ·å¯ä»¥åŒæ—¶å¤„ç† Python åŸç”Ÿ `list` å’Œ pandas è½¬æ¢åçš„ `numpy.ndarray`ã€‚

### å®Œæ•´ä¿®æ”¹

```python
def build_lists(row):
    # Prefer standard annotations
    if "annotations" in row and row["annotations"] is not None:
        ann = row["annotations"]
        # Handle both list and numpy.ndarray (pandas may convert lists to arrays)
        if isinstance(ann, (list, np.ndarray)):  # â† å…³é”®ä¿®æ”¹
            texts = []
            sources = []
            for a in ann:
                if isinstance(a, dict):
                    t = a.get("text") or a.get("target") or a.get("reference")
                    s = a.get("source", "")
                    if isinstance(t, str) and t.strip():
                        texts.append(t)
                        sources.append(s)
                elif isinstance(a, str):
                    texts.append(a)
                    sources.append("")
            return sources, texts
        # ... å…¶ä½™ä»£ç ä¿æŒä¸å˜
```

## ğŸ“‹ æ‰§è¡Œæ­¥éª¤

### 1. ä¸Šä¼ ä¿®æ”¹åçš„æ–‡ä»¶åˆ°è¿œç¨‹æœåŠ¡å™¨

ç¡®ä¿ `mamba-peft/dataset/dart_data.py` å·²æ›´æ–°ã€‚

### 2. éªŒè¯ä¿®å¤ï¼ˆå¯é€‰ä½†æ¨èï¼‰

```bash
cd /home/user/mzs_h/code/zh-LAT-peft
python verify_dart_fix.py
```

é¢„æœŸè¾“å‡ºï¼š
```
âœ“ load_df() è¿”å›: 30526 è¡Œ
âœ“âœ“âœ“ ä¿®å¤æˆåŠŸï¼æ•°æ®åŠ è½½æ­£å¸¸ï¼
âœ“ åˆå§‹åŒ–æˆåŠŸ: 10 ä¸ªæ ·æœ¬
âœ“âœ“âœ“ å®Œæ•´åˆå§‹åŒ–æˆåŠŸï¼
æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼DART æ•°æ®é›†ä¿®å¤æˆåŠŸï¼
```

### 3. æ¸…ç†æ—§ç¼“å­˜

```bash
cd /home/user/mzs_h/code/zh-LAT-peft/mamba-peft
rm -f data/GEM_dart/cache_GEM_dart_train*.pkl
rm -f data/GEM_dart/parts/cache_GEM_dart_train_part_*.pkl
```

### 4. é‡æ–°è¿è¡Œè®­ç»ƒ

```bash
cd /home/user/mzs_h/code/zh-LAT-peft/mamba-peft/scripts/train/new

PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True \
TOKENIZERS_PARALLELISM=false OMP_NUM_THREADS=1 MKL_NUM_THREADS=1 \
NUM_DATA_WORKERS=4 \
GRADIENT_CHECKPOINTING=true \
LOGITS_TO_KEEP=1 \
HP_EVAL_STEPS=2000 HP_SAVE_STEPS=2000 HP_LOGGING_STEPS=200 \
EVAL_GEN=1 EVAL_GEN_MAX_LENGTH=128 EVAL_GEN_MIN_LENGTH=5 EVAL_GEN_NUM_BEAMS=5 \
./gla_batch_tmux.sh --suite E10 --round all \
  --pairs "87:dart" \
  --gpus "1" \
  --gpu-plan "1"
```

## ğŸ‰ é¢„æœŸç»“æœ

ä¿®å¤åï¼Œè®­ç»ƒå¯åŠ¨æ—¶åº”è¯¥çœ‹åˆ°ï¼š

```
Loading GLA model: ...
Parallel processing: 0it [00:00, ?it/s]
Wrote data/GEM_dart/parts/cache_GEM_dart_train_part_000.pkl
Wrote data/GEM_dart/parts/cache_GEM_dart_train_part_001.pkl
...
Aggregating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:00<00:00, ...]
Dropping last batch
Trainable parameters: ...
trainable params: 2,752,512 || all params: 1,368,266,752 || trainable%: 0.201...
Loaded model
[è®­ç»ƒå¾ªç¯å¼€å§‹ï¼Œä¸å†æŠ¥ num_samples=0]
```

## ğŸ” æŠ€æœ¯ç»†èŠ‚

### ä¸ºä»€ä¹ˆä¼šå‡ºç°è¿™ä¸ªé—®é¢˜ï¼Ÿ

1. **HF Datasets çš„è¡Œä¸º**ï¼š`datasets.Dataset.to_pandas()` ä¼šå°†åµŒå¥—çš„ `list` å­—æ®µè½¬æ¢ä¸º `numpy.ndarray` ä»¥æé«˜æ€§èƒ½
2. **ç±»å‹æ£€æŸ¥çš„é™·é˜±**ï¼š`isinstance(arr, list)` å¯¹ `numpy.ndarray` è¿”å› `False`
3. **é™é»˜å¤±è´¥**ï¼šä»£ç æ²¡æœ‰æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯è¿”å›ç©ºåˆ—è¡¨ï¼Œå¯¼è‡´éš¾ä»¥è°ƒè¯•

### ä¸ºä»€ä¹ˆä¹‹å‰çš„æµ‹è¯•è„šæœ¬æˆåŠŸäº†ï¼Ÿ

åœ¨ `trace_build_lists.py` ä¸­ï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨ `load_dataset("json", ...)` å¹¶ç«‹å³è½¬æ¢ä¸º pandasï¼Œè¿™ç§æƒ…å†µä¸‹ pandas ä¿ç•™äº†åŸå§‹çš„ `list` ç±»å‹ã€‚ä½†åœ¨ `DartDataset.load_hf_dataset_split()` ä¸­ï¼ŒDataset å¯èƒ½ç»è¿‡äº†å…¶ä»–å¤„ç†ï¼ˆå¦‚ `train_test_split`ï¼‰ï¼Œå¯¼è‡´ç±»å‹è½¬æ¢ã€‚

### å…¶ä»–å¯èƒ½å—å½±å“çš„æ•°æ®é›†

è¿™ä¸ªé—®é¢˜å¯èƒ½ä¹Ÿå½±å“å…¶ä»–ä½¿ç”¨ç±»ä¼¼æ¨¡å¼çš„æ•°æ®é›†ï¼ˆSAMSumã€Spider ç­‰ï¼‰ã€‚å»ºè®®æ£€æŸ¥å¹¶åº”ç”¨ç›¸åŒçš„ä¿®å¤ã€‚

## ğŸ“ ç›¸å…³æ–‡ä»¶

- **ä¿®å¤çš„æ–‡ä»¶**ï¼š`mamba-peft/dataset/dart_data.py`
- **æ”¹è¿›çš„æ–‡ä»¶**ï¼š`mamba-peft/utils/parallel_processor_fs.py`ï¼ˆæ·»åŠ äº†é”™è¯¯å¤„ç†ï¼‰
- **éªŒè¯è„šæœ¬**ï¼š
  - `verify_dart_fix.py` - å¿«é€ŸéªŒè¯ä¿®å¤
  - `test_dartdataset_full.py` - å®Œæ•´æµ‹è¯•
  - `compare_loading_methods.py` - å¯¹æ¯”åŠ è½½æ–¹å¼
  - `trace_build_lists.py` - è¿½è¸ª build_lists æ‰§è¡Œ

## ğŸš€ åç»­å»ºè®®

1. **æ£€æŸ¥å…¶ä»–æ•°æ®é›†**ï¼šSAMSum å’Œ Spider å¯èƒ½æœ‰ç›¸åŒé—®é¢˜
2. **æ·»åŠ å•å…ƒæµ‹è¯•**ï¼šä¸º `build_lists` æ·»åŠ æµ‹è¯•ï¼Œè¦†ç›– `list` å’Œ `numpy.ndarray` ä¸¤ç§æƒ…å†µ
3. **æ”¹è¿›é”™è¯¯å¤„ç†**ï¼šåœ¨ `build_lists` ä¸­æ·»åŠ æ—¥å¿—ï¼Œè®°å½•å¤„ç†çš„æ•°æ®ç±»å‹

## ğŸ“ ç»éªŒæ•™è®­

1. **ç±»å‹æ£€æŸ¥è¦å…¨é¢**ï¼šå¤„ç† pandas DataFrame æ—¶ï¼Œè¦è€ƒè™‘ `numpy.ndarray`
2. **è°ƒè¯•è¦æ·±å…¥**ï¼šä¸è¦æ»¡è¶³äºè¡¨é¢ç°è±¡ï¼Œè¦è¿½è¸ªåˆ°æ ¹æœ¬åŸå› 
3. **æµ‹è¯•è¦çœŸå®**ï¼šæµ‹è¯•ç¯å¢ƒè¦å°½å¯èƒ½æ¥è¿‘å®é™…è¿è¡Œç¯å¢ƒ
4. **é”™è¯¯å¤„ç†è¦å®Œå–„**ï¼šé™é»˜å¤±è´¥æ¯”æ˜¾å¼é”™è¯¯æ›´éš¾è°ƒè¯•

---

**ä¿®å¤å®Œæˆï¼** ğŸ‰

ç°åœ¨ DART æ•°æ®é›†åº”è¯¥å¯ä»¥æ­£å¸¸è®­ç»ƒäº†ã€‚å¦‚æœè¿˜æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—ä¸­çš„è¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼ˆå¾—ç›Šäºæ”¹è¿›çš„ `parallel_processor_fs.py`ï¼‰ã€‚

